{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8ZLPyqufuO-"
   },
   "source": [
    "# üìò Final ‚Äì Visi√≥n Computacional - Modalidad Online\n",
    "---\n",
    "\n",
    "**Ejercicio pr√°ctico final:**  \n",
    "Para el video que se incluye en esta carpeta es necesario generar otro video donde en el lateral derecho TODO EL TIEMPO se marque si est√°n encendidas las luces del tablero relacionadas a freno de mano, guino izquierda, guino derecha, balizas, luces altas, luces de posici√≥n. Adem√°s se debe indicar el valor de las revoluciones.\n",
    "\n",
    "El texto que debe aparecer a la derecha ser√≠a:\n",
    "* Freno de Mano: SI/NO\n",
    "* Guino Izquierda: SI/NO\n",
    "* Guino Derecha: SI/NO\n",
    "* Balizas: SI/NO\n",
    "* Luces Altas: SI/NO\n",
    "* Luces Posicion: SI/NO\n",
    "* R.P.M.: NNNN\n",
    "\n",
    "No se puede usar YOLO, PYTORCH ni ning√∫n tipo de red neuronal.  \n",
    "El valor de las revoluciones puede ser aproximado.  \n",
    "Van a tener que subir el video resultante y el archivo de colab con el cual lo resolvieron.\n",
    "\n",
    "---\n",
    "\n",
    "**Autor/es:**  \n",
    "- Juan Cruz, Rey  \n",
    "\n",
    "**Profesor:**  \n",
    "Jorge Mart√≠n Acosta\n",
    "\n",
    "**Instituci√≥n:**  \n",
    "Universidad de Palermo\n",
    "\n",
    "**Fecha:**  \n",
    "18 de Diciembre 2025\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RVdAzHcfuO_"
   },
   "source": [
    "## 1. Instalaci√≥n de Dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6B4Dx6nyfuO_"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install opencv-python numpy pillow ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zz3KcZm-fuPA"
   },
   "source": [
    "## 2. Importar Librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "994b4562fuPA"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "from PIL import Image\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E30hZo74fuPB"
   },
   "source": [
    "## 3. Configuraci√≥n de Rutas y Colores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "KlATQ-TvfuPB"
   },
   "outputs": [],
   "source": [
    "# Rutas\n",
    "VIDEO_PATH = \"video.mov\"\n",
    "\n",
    "# Opciones de visualizaci√≥n\n",
    "MOSTRAR_SOLO_DETECTADAS = True  # True: Solo muestra ROIs cuando estan detectadas | False: Muestra todas siempre\n",
    "HABILITAR_VISUALIZACION = False   # True: Ejecuta visualizacion en notebook | False: Salta visualizacion\n",
    "\n",
    "# Colores (BGR)\n",
    "COLOR_DETECTADO = (0, 255, 255)      # Amarillo\n",
    "COLOR_ON = (0, 255, 0)               # Verde\n",
    "COLOR_OFF = (0, 0, 255)              # Rojo\n",
    "COLOR_INFO = (128, 128, 128)         # Gris\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8tgh7cO5fuPB"
   },
   "source": [
    "## 4. Configuraci√≥n de ROIs\n",
    "\n",
    "**Ejecuta esta celda para definir las √°reas de inter√©s (ROIs) y par√°metros de detecci√≥n.**\n",
    "\n",
    "Este diccionario contiene todas las se√±ales a detectar con sus coordenadas, rangos de color y umbrales de brillo que permitir√°n detectar las se√±ales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q59M-sEUfuPB",
    "outputId": "1eba852b-6337-4090-829c-266fe965b880"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ROIs configuradas: 7 se√±ales\n",
      "\n",
      "Se√±ales disponibles:\n",
      "  - Guino Izquierda\n",
      "  - Guino Derecha\n",
      "  - Balizas\n",
      "  - Freno de Mano\n",
      "  - Luces Altas\n",
      "  - Luces Posicion\n",
      "  - R.P.M.\n"
     ]
    }
   ],
   "source": [
    "# Configuraci√≥n de las ROIs y par√°metros de detecci√≥n\n",
    "rois_data = {\n",
    "    \"Guino_Izquierda\": {\n",
    "        \"nombre_display\": \"Guino Izquierda\",\n",
    "        \"roi\": [250, 650, 100, 100],\n",
    "        \"color_rgb\": [0, 255, 0],\n",
    "        \"tipo\": \"parpadeo\",\n",
    "        \"color_hsv_bajo\": [40, 100, 100],\n",
    "        \"color_hsv_alto\": [80, 255, 255],\n",
    "        \"umbral_brillo\": 80,\n",
    "        \"descripcion\": \"Luz verde lateral izquierda - parpadea 2-4s\"\n",
    "    },\n",
    "    \"Guino_Derecha\": {\n",
    "        \"nombre_display\": \"Guino Derecha\",\n",
    "        \"roi\": [1660, 540, 70, 70],\n",
    "        \"color_rgb\": [0, 255, 0],\n",
    "        \"tipo\": \"parpadeo\",\n",
    "        \"color_hsv_bajo\": [40, 100, 100],\n",
    "        \"color_hsv_alto\": [80, 255, 255],\n",
    "        \"umbral_brillo\": 80,\n",
    "        \"descripcion\": \"Luz verde lateral derecha - parpadea 5-9s\"\n",
    "    },\n",
    "    \"Balizas\": {\n",
    "        \"nombre_display\": \"Balizas\",\n",
    "        \"tipo\": \"combinacion\",\n",
    "        \"color_rgb\": [255, 255, 0],\n",
    "        \"roi_izq\": [180, 520, 60, 60],\n",
    "        \"roi_der\": [1140, 420, 60, 60],\n",
    "        \"descripcion\": \"Ambos guinos parpadeando simult√°neamente - 10-13s\"\n",
    "    },\n",
    "    \"Freno_Mano\": {\n",
    "        \"nombre_display\": \"Freno de Mano\",\n",
    "        \"roi\": [1040, 340, 80, 80],\n",
    "        \"color_rgb\": [255, 0, 0],\n",
    "        \"tipo\": \"luz_fija\",\n",
    "        \"color_hsv_bajo\": [0, 100, 100],\n",
    "        \"color_hsv_alto\": [10, 255, 255],\n",
    "        \"umbral_brillo\": 100,\n",
    "        \"descripcion\": \"Luz roja superior derecha - visible 14-16s\"\n",
    "    },\n",
    "    \"Luces_Altas\": {\n",
    "        \"nombre_display\": \"Luces Altas\",\n",
    "        \"roi\": [770, 700, 60, 60],\n",
    "        \"color_rgb\": [0, 0, 255],\n",
    "        \"tipo\": \"luz_fija\",\n",
    "        \"color_hsv_bajo\": [100, 150, 100],\n",
    "        \"color_hsv_alto\": [130, 255, 255],\n",
    "        \"umbral_brillo\": 80,\n",
    "        \"descripcion\": \"Luz azul inferior central - parpadea 17-24s\"\n",
    "    },\n",
    "    \"Luces_Posicion\": {\n",
    "        \"nombre_display\": \"Luces Posicion\",\n",
    "        \"roi\": [680, 740, 60, 50],\n",
    "        \"color_rgb\": [0, 255, 0],\n",
    "        \"tipo\": \"luz_fija\",\n",
    "        \"color_hsv_bajo\": [40, 100, 100],\n",
    "        \"color_hsv_alto\": [80, 255, 255],\n",
    "        \"umbral_brillo\": 80,\n",
    "        \"descripcion\": \"Luz verde inferior central - parpadea 25-28s\"\n",
    "    },\n",
    "    \"RPM\": {\n",
    "        \"nombre_display\": \"R.P.M.\",\n",
    "        \"roi_completa\": [470, 550, 300, 300],\n",
    "        \"roi_centro\": [320, 420, 60, 60],\n",
    "        \"color_rgb\": [255, 165, 0],\n",
    "        \"tipo\": \"aguja_angular\",\n",
    "        \"color_aguja_hsv_bajo\": [12, 100, 100],\n",
    "        \"color_aguja_hsv_alto\": [22, 255, 255],\n",
    "        \"descripcion\": \"Tac√≥metro 0-4000 RPM - Gira anti-horario, √°ngulo disminuye: 248¬∞ (0 RPM) hasta 164¬∞ (4000 RPM, marca '4')\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"ROIs configuradas: {len(rois_data)} se√±ales\")\n",
    "print(\"\\nSe√±ales disponibles:\")\n",
    "for nombre, datos in rois_data.items():\n",
    "    nombre_display = datos.get('nombre_display', nombre)\n",
    "    print(f\"  - {nombre_display}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYOnB7FZfuPC"
   },
   "source": [
    "## 5. Verificar que exista video Local\n",
    "\n",
    "El video `video.mov` debe estar en el mismo directorio que este notebook para poder ejecutar el script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "04vSDKwvfuPC",
    "outputId": "36017539-2034-405d-c6b0-307bf4bace4e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "‚úÖ Video encontrado: video.mov\n",
      "   Resoluci√≥n: 1920x1080\n",
      "   FPS: 29.987282746926663\n",
      "   Duraci√≥n: 39.3 segundos\n",
      "   Total frames: 1179\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if os.path.exists(VIDEO_PATH):\n",
    "    print(f\"‚úÖ Video encontrado: {VIDEO_PATH}\")\n",
    "\n",
    "    # Obtener informaci√≥n del video\n",
    "    cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "    if cap.isOpened():\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        duracion = total_frames / fps if fps > 0 else 0\n",
    "\n",
    "        print(f\"   Resoluci√≥n: {width}x{height}\")\n",
    "        print(f\"   FPS: {fps}\")\n",
    "        print(f\"   Duraci√≥n: {duracion:.1f} segundos\")\n",
    "        print(f\"   Total frames: {total_frames}\")\n",
    "        cap.release()\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  No se pudo abrir el video\")\n",
    "else:\n",
    "    print(f\"‚ùå Video no encontrado: {VIDEO_PATH}\")\n",
    "    print(f\"   Aseg√∫rate de que el archivo est√© en: {os.path.abspath(VIDEO_PATH)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bV1BihyvfuPD"
   },
   "source": [
    "## 6. Funciones de Detecci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7uO94IEOfuPD"
   },
   "outputs": [],
   "source": [
    "def detectar_senal_en_roi(roi_frame, datos_roi):\n",
    "    \"\"\"Detecta si hay una se√±al activa en la ROI\"\"\"\n",
    "    if datos_roi.get(\"tipo\") == \"combinacion\":\n",
    "        return False\n",
    "\n",
    "    # El RPM se maneja por separado\n",
    "    if datos_roi.get(\"tipo\") == \"aguja_angular\":\n",
    "        return False\n",
    "\n",
    "    umbral_brillo = datos_roi.get(\"umbral_brillo\", 80)\n",
    "    hsv = cv2.cvtColor(roi_frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Si hay rangos HSV definidos, SOLO usar detecci√≥n por color (m√°s precisa)\n",
    "    if \"color_hsv_bajo\" in datos_roi and \"color_hsv_alto\" in datos_roi:\n",
    "        hsv_bajo = np.array(datos_roi[\"color_hsv_bajo\"])\n",
    "        hsv_alto = np.array(datos_roi[\"color_hsv_alto\"])\n",
    "        mask = cv2.inRange(hsv, hsv_bajo, hsv_alto)\n",
    "        porcentaje_color = (np.sum(mask > 0) / mask.size) * 100\n",
    "\n",
    "        # Requiere al menos 5% de p√≠xeles con el color correcto\n",
    "        return porcentaje_color > 5\n",
    "\n",
    "    # Solo si NO hay rangos HSV, usar detecci√≥n por brillo (fallback)\n",
    "    gray = cv2.cvtColor(roi_frame, cv2.COLOR_BGR2GRAY)\n",
    "    brillo_medio = np.mean(gray)\n",
    "\n",
    "    return brillo_medio > umbral_brillo\n",
    "\n",
    "\n",
    "def detectar_todas_las_senales(frame, rois_data):\n",
    "    \"\"\"Detecta el estado de todas las se√±ales en el frame\"\"\"\n",
    "    estados_deteccion = {}\n",
    "\n",
    "    for nombre, datos in rois_data.items():\n",
    "        if datos.get(\"tipo\") == \"combinacion\":\n",
    "            continue\n",
    "\n",
    "        # Manejar RPM por separado\n",
    "        if datos.get(\"tipo\") == \"aguja_angular\" and nombre == \"RPM\":\n",
    "            rpm_actual = detectar_rpm_tacometro(frame, datos)\n",
    "            # Marcar como detectado si hay movimiento (RPM > umbral)\n",
    "            estados_deteccion[nombre] = rpm_tiene_movimiento(rpm_actual)\n",
    "            # Guardar el valor RPM para mostrarlo\n",
    "            estados_deteccion[f\"{nombre}_valor\"] = rpm_actual\n",
    "            continue\n",
    "\n",
    "        roi = obtener_coordenadas_roi(datos)\n",
    "        if roi is None:\n",
    "            continue\n",
    "\n",
    "        x, y, w, h = roi\n",
    "        roi_frame = frame[y:y+h, x:x+w]\n",
    "\n",
    "        if roi_frame.size > 0:\n",
    "            estados_deteccion[nombre] = detectar_senal_en_roi(roi_frame, datos)\n",
    "\n",
    "    return estados_deteccion\n",
    "\n",
    "\n",
    "def detectar_balizas(estados_deteccion):\n",
    "    \"\"\"Detecta si las balizas est√°n activas (ambos guinos encendidos)\"\"\"\n",
    "    return (estados_deteccion.get(\"Guino_Izquierda\", False) and\n",
    "            estados_deteccion.get(\"Guino_Derecha\", False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "XhSKMAdYfuPD"
   },
   "outputs": [],
   "source": [
    "# Configuraci√≥n del tac√≥metro\n",
    "RPM_MAX_VALUE = 4000   # En este video, la aguja solo llega hasta la marca \"4\" (4000 RPM)\n",
    "RPM_START_ANGLE = 248  # √Ångulo en grados para 0 RPM (reposo)\n",
    "RPM_END_ANGLE = 164    # √Ångulo en grados para 4000 RPM (m√°ximo observado en el video)\n",
    "RPM_CENTER_X = 670     # Centro X del tac√≥metro\n",
    "RPM_CENTER_Y = 680     # Centro Y del tac√≥metro\n",
    "RPM_UMBRAL_MINIMO = 300  # RPM m√≠nimo para considerar que hay movimiento\n",
    "\n",
    "\n",
    "def detectar_rpm_tacometro(frame, datos_roi):\n",
    "    \"\"\"\n",
    "    Detecta el valor de RPM analizando el √°ngulo de la aguja\n",
    "\n",
    "    El tac√≥metro gira en sentido ANTI-HORARIO (√°ngulo disminuye al aumentar RPM):\n",
    "    - 0 RPM: ~248¬∞ (aguja en reposo, arriba-izquierda)\n",
    "    - 4000 RPM: ~164¬∞ (aguja al m√°ximo en este video, cerca de la marca \"4\")\n",
    "    - Rango total: 84¬∞ de rotaci√≥n\n",
    "\n",
    "    Nota: El tac√≥metro f√≠sico tiene marcas hasta 8 (8000 RPM), pero en este\n",
    "    video la aguja solo llega hasta aproximadamente la marca 4 (4000 RPM).\n",
    "\n",
    "    Args:\n",
    "        frame: Frame del video completo\n",
    "        datos_roi: Datos de configuraci√≥n del ROI del tac√≥metro\n",
    "\n",
    "    Returns:\n",
    "        int: Valor de RPM detectado (0-4000)\n",
    "    \"\"\"\n",
    "    # Obtener ROI completa del tac√≥metro (solo contiene la aguja)\n",
    "    roi_coords = datos_roi.get(\"roi_completa\")\n",
    "    if roi_coords is None:\n",
    "        return 0\n",
    "\n",
    "    x_rpm, y_rpm, w_rpm, h_rpm = roi_coords\n",
    "    gauge_img = frame[y_rpm:y_rpm+h_rpm, x_rpm:x_rpm+w_rpm].copy()\n",
    "\n",
    "    # Convertir a HSV para detectar la aguja naranja\n",
    "    hsv = cv2.cvtColor(gauge_img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # M√°scara para detectar aguja naranja\n",
    "    hsv_bajo = np.array(datos_roi.get(\"color_aguja_hsv_bajo\", [12, 100, 100]))\n",
    "    hsv_alto = np.array(datos_roi.get(\"color_aguja_hsv_alto\", [22, 255, 255]))\n",
    "\n",
    "    mask = cv2.inRange(hsv, hsv_bajo, hsv_alto)\n",
    "\n",
    "    # Encontrar contornos\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if not contours:\n",
    "        return 0\n",
    "\n",
    "    # SIMPLIFICADO: Como el ROI solo contiene la aguja,\n",
    "    # tomamos el contorno m√°s grande\n",
    "    contorno_aguja = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # Si el contorno es muy peque√±o, probablemente es ruido\n",
    "    if cv2.contourArea(contorno_aguja) < 20:\n",
    "        return 0\n",
    "\n",
    "    # Centro del tac√≥metro (relativo al ROI)\n",
    "    center_x_roi = RPM_CENTER_X - x_rpm\n",
    "    center_y_roi = RPM_CENTER_Y - y_rpm\n",
    "\n",
    "    # Encontrar el punto m√°s alejado del centro (punta de la aguja)\n",
    "    max_dist = 0\n",
    "    tip_x_roi = center_x_roi\n",
    "    tip_y_roi = center_y_roi\n",
    "\n",
    "    for point in contorno_aguja:\n",
    "        px, py = point[0]\n",
    "        dist = math.sqrt((px - center_x_roi)**2 + (py - center_y_roi)**2)\n",
    "        if dist > max_dist:\n",
    "            max_dist = dist\n",
    "            tip_x_roi = px\n",
    "            tip_y_roi = py\n",
    "\n",
    "    # Calcular √°ngulo usando atan2\n",
    "    angle_rad = math.atan2(center_y_roi - tip_y_roi, tip_x_roi - center_x_roi)\n",
    "    angle_deg = (angle_rad * 180 / math.pi) % 360\n",
    "\n",
    "    # Mapear √°ngulo a RPM (√°ngulo DISMINUYE al aumentar RPM: 248¬∞ -> 164¬∞)\n",
    "    # Mayor √°ngulo = menor RPM\n",
    "    angle_from_max = RPM_START_ANGLE - angle_deg  # Distancia desde 0 RPM\n",
    "    angle_span = RPM_START_ANGLE - RPM_END_ANGLE  # 84¬∞ total\n",
    "\n",
    "    # Calcular RPM con interpolaci√≥n lineal\n",
    "    if angle_from_max <= 0:\n",
    "        # √Ångulo >= START_ANGLE, estamos en 0 RPM o menos\n",
    "        rpm = 0\n",
    "    elif angle_from_max >= angle_span:\n",
    "        # √Ångulo <= END_ANGLE, estamos en RPM m√°ximo o m√°s\n",
    "        rpm = RPM_MAX_VALUE\n",
    "    else:\n",
    "        # Interpolaci√≥n lineal\n",
    "        rpm = int((angle_from_max / angle_span) * RPM_MAX_VALUE)\n",
    "\n",
    "    return rpm\n",
    "\n",
    "\n",
    "rpm_anterior = 0\n",
    "\n",
    "def rpm_tiene_movimiento(rpm_actual, umbral_minimo=RPM_UMBRAL_MINIMO):\n",
    "    \"\"\"\n",
    "    Determina si hay movimiento en el tac√≥metro\n",
    "\n",
    "    Args:\n",
    "        rpm_actual: Valor actual de RPM\n",
    "        umbral_minimo: RPM m√≠nimo para considerar que hay movimiento\n",
    "\n",
    "    Returns:\n",
    "        bool: True si RPM > umbral_minimo (indica que la aguja se movi√≥)\n",
    "    \"\"\"\n",
    "    global rpm_anterior\n",
    "\n",
    "    # Hay movimiento si el RPM es mayor al umbral m√≠nimo\n",
    "    hay_movimiento = rpm_actual > umbral_minimo\n",
    "\n",
    "    # Actualizar RPM anterior\n",
    "    rpm_anterior = rpm_actual\n",
    "\n",
    "    return hay_movimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-JJvdKSfuPE"
   },
   "source": [
    "## 7. Funciones de Utilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "vq6Mt89cfuPE"
   },
   "outputs": [],
   "source": [
    "def obtener_coordenadas_roi(datos_roi):\n",
    "    \"\"\"Obtiene las coordenadas (x, y, w, h) de una ROI\"\"\"\n",
    "    if \"roi\" in datos_roi and datos_roi[\"roi\"] is not None:\n",
    "        return datos_roi[\"roi\"]\n",
    "    elif \"roi_completa\" in datos_roi:\n",
    "        return datos_roi[\"roi_completa\"]\n",
    "    return None\n",
    "\n",
    "\n",
    "def obtener_color_roi(datos_roi):\n",
    "    \"\"\"Obtiene el color BGR de una ROI desde el JSON\"\"\"\n",
    "    if \"color_rgb\" in datos_roi and datos_roi[\"color_rgb\"] is not None:\n",
    "        rgb = datos_roi[\"color_rgb\"]\n",
    "        return (rgb[2], rgb[1], rgb[0])  # Convertir RGB a BGR\n",
    "    elif \"color_bgr\" in datos_roi and datos_roi[\"color_bgr\"] is not None:\n",
    "        return tuple(datos_roi[\"color_bgr\"])\n",
    "    # Blanco por defecto (nunca deber√≠a llegar aqu√≠)\n",
    "    return (255, 255, 255)\n",
    "\n",
    "\n",
    "def preparar_lista_estados(estados_deteccion, balizas_activas, rois_data):\n",
    "    \"\"\"Prepara la lista de estados de todas las se√±ales para mostrar\"\"\"\n",
    "    lista_estados = []\n",
    "\n",
    "    for nombre_tecnico, datos in rois_data.items():\n",
    "        nombre_display = datos.get(\"nombre_display\", nombre_tecnico)\n",
    "\n",
    "        if nombre_tecnico == \"Balizas\":\n",
    "            # Balizas: mostrar su estado real\n",
    "            lista_estados.append((nombre_display, balizas_activas))\n",
    "        elif nombre_tecnico in [\"Guino_Izquierda\", \"Guino_Derecha\"]:\n",
    "            # Gui√±os: si hay balizas activas, mostrar OFF\n",
    "            # Si NO hay balizas, mostrar su estado real\n",
    "            if balizas_activas:\n",
    "                lista_estados.append((nombre_display, False))\n",
    "            else:\n",
    "                estado = estados_deteccion.get(nombre_tecnico, False)\n",
    "                lista_estados.append((nombre_display, estado))\n",
    "        elif nombre_tecnico == \"RPM\":\n",
    "            estado = estados_deteccion.get(nombre_tecnico, False)\n",
    "            rpm_valor = estados_deteccion.get(f\"{nombre_tecnico}_valor\", 0)\n",
    "            # RPM tiene formato especial: (nombre, estado, valor_rpm)\n",
    "            lista_estados.append((nombre_display, estado, rpm_valor))\n",
    "        else:\n",
    "            estado = estados_deteccion.get(nombre_tecnico, False)\n",
    "            lista_estados.append((nombre_display, estado))\n",
    "\n",
    "    return lista_estados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0flqhe7GfuPE"
   },
   "source": [
    "## 8. Funciones de Visualizaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UTSn_Rl0fuPE"
   },
   "outputs": [],
   "source": "def dibujar_roi(frame, nombre, datos_roi, estado_detectado, balizas_activas):\n    \"\"\"Dibuja una ROI individual en el frame\"\"\"\n    # Si la bandera est√° activa, solo dibujar si est√° detectada\n    if MOSTRAR_SOLO_DETECTADAS and not estado_detectado:\n        return\n\n    roi = obtener_coordenadas_roi(datos_roi)\n    if roi is None:\n        return\n\n    x, y, w, h = roi\n    color_normal = obtener_color_roi(datos_roi)\n    color = COLOR_DETECTADO if estado_detectado else color_normal\n    grosor = 4 if estado_detectado else 2\n\n    cv2.rectangle(frame, (x, y), (x+w, y+h), color, grosor)\n\n    # Etiqueta\n    if balizas_activas and nombre in [\"Guino_Izquierda\", \"Guino_Derecha\"]:\n        etiqueta = \"BALIZAS [DETECTADO]\"\n    elif estado_detectado:\n        etiqueta = f\"{nombre} [DETECTADO]\"\n    else:\n        etiqueta = nombre\n\n    cv2.putText(frame, etiqueta, (x, y-10),\n               cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n\n\ndef dibujar_todas_las_rois(frame, rois_data, estados_deteccion, balizas_activas):\n    \"\"\"Dibuja todas las ROIs en el frame\"\"\"\n    for nombre, datos in rois_data.items():\n        if datos.get(\"tipo\") == \"combinacion\":\n            continue\n\n        estado_detectado = estados_deteccion.get(nombre, False)\n        dibujar_roi(frame, nombre, datos, estado_detectado, balizas_activas)\n\n\ndef dibujar_panel_estados(frame, lista_estados):\n    \"\"\"Dibuja el panel de estados en el lateral derecho\"\"\"\n    # Obtener dimensiones del frame\n    frame_height, frame_width = frame.shape[:2]\n\n    line_height = 30\n    font_scale = 0.6\n    font_thickness = 2\n    padding = 10\n\n    # Calcular tama√±o del panel\n    max_width = 0\n    for item in lista_estados:\n        # Verificar si es RPM (tupla de 3 elementos)\n        if len(item) == 3:\n            nombre_display, _, rpm_valor = item\n            texto = f\"{nombre_display}: {rpm_valor}\"\n        else:\n            nombre_display = item[0]\n            texto = f\"{nombre_display}: NO\"\n\n        (text_w, _), _ = cv2.getTextSize(texto, cv2.FONT_HERSHEY_SIMPLEX,\n                                         font_scale, font_thickness)\n        max_width = max(max_width, text_w)\n\n    panel_width = max_width + padding * 2\n    panel_height = len(lista_estados) * line_height + padding * 2\n\n    # POSICION A LA DERECHA\n    panel_x = frame_width - panel_width - 10  # 10px desde el borde derecho\n    panel_y = 10\n\n    # Fondo negro\n    cv2.rectangle(frame,\n                 (panel_x, panel_y),\n                 (panel_x + panel_width, panel_y + panel_height),\n                 (0, 0, 0), -1)\n\n    # Dibujar l√≠neas de estado\n    for i, item in enumerate(lista_estados):\n        y_pos = panel_y + padding + (i + 1) * line_height - 5\n\n        # Verificar si es RPM (tupla de 3 elementos)\n        if len(item) == 3:\n            nombre_display, estado, rpm_valor = item\n            color_estado = COLOR_ON if estado else COLOR_OFF\n            texto = f\"{nombre_display}: {rpm_valor}\"  # Sin duplicar RPM\n        else:\n            nombre_display, estado = item\n            color_estado = COLOR_ON if estado else COLOR_OFF\n            estado_texto = \"SI\" if estado else \"NO\"  # Cambiado de ON/OFF a SI/NO\n            texto = f\"{nombre_display}: {estado_texto}\"\n\n        cv2.putText(frame, texto, (panel_x + padding, y_pos),\n                   cv2.FONT_HERSHEY_SIMPLEX, font_scale, color_estado, font_thickness)\n\n\n\n\ndef dibujar_tiempo_video(frame, panel_height, frame_actual, fps, duracion):\n    \"\"\"Dibuja el tiempo actual del video en el lateral derecho, debajo del panel\"\"\"\n    # Obtener dimensiones del frame\n    frame_height, frame_width = frame.shape[:2]\n\n    tiempo_actual = frame_actual / fps if fps > 0 else 0\n    tiempo_text = f\"Tiempo: {tiempo_actual:.1f}s / {duracion:.1f}s\"\n\n    # Configuraci√≥n mejorada\n    font_scale = 0.65\n    font_thickness = 2\n    padding = 8\n\n    # Calcular tama√±o del texto\n    (text_w, text_h), _ = cv2.getTextSize(tiempo_text, cv2.FONT_HERSHEY_SIMPLEX,\n                                           font_scale, font_thickness)\n\n    # Posici√≥n a la derecha, debajo del panel\n    info_width = text_w + padding * 2\n    info_height = text_h + padding * 2 + 10\n\n    panel_x = frame_width - info_width - 10  # Alineado con el panel derecho\n    panel_y = 10\n    info_y = panel_y + panel_height + 10  # Debajo del panel de estados\n\n    # Fondo negro\n    cv2.rectangle(frame,\n                 (panel_x, info_y),\n                 (panel_x + info_width, info_y + info_height),\n                 (0, 0, 0), -1)\n\n    # Borde gris sutil para mejor definici√≥n\n    cv2.rectangle(frame,\n                 (panel_x, info_y),\n                 (panel_x + info_width, info_y + info_height),\n                 (80, 80, 80), 1)\n\n    # Texto blanco para mejor contraste\n    cv2.putText(frame, tiempo_text,\n               (panel_x + padding, info_y + text_h + padding + 5),\n               cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), font_thickness)"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWazXg26fuPE"
   },
   "source": [
    "## 9. Funci√≥n Principal de Procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "KNmCL80ZfuPE"
   },
   "outputs": [],
   "source": [
    "def procesar_frame(frame, rois_data, frame_actual, fps, duracion):\n",
    "    \"\"\"Procesa un frame individual y retorna el frame con las detecciones dibujadas\"\"\"\n",
    "    # Detectar se√±ales\n",
    "    estados_deteccion = detectar_todas_las_senales(frame, rois_data)\n",
    "    balizas_activas = detectar_balizas(estados_deteccion)\n",
    "\n",
    "    # Dibujar elementos\n",
    "    dibujar_todas_las_rois(frame, rois_data, estados_deteccion, balizas_activas)\n",
    "\n",
    "    lista_estados = preparar_lista_estados(estados_deteccion, balizas_activas, rois_data)\n",
    "    dibujar_panel_estados(frame, lista_estados)\n",
    "\n",
    "    panel_height = len(lista_estados) * 30 + 20\n",
    "    dibujar_tiempo_video(frame, panel_height, frame_actual, fps, duracion)\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFnoVCd5fuPF"
   },
   "source": [
    "## 10. Visualizaci√≥n en Jupyter Local\n",
    "\n",
    "Esta funci√≥n muestra el video frame por frame en el notebook.\n",
    "\n",
    "**Nota**: En Jupyter local, la visualizaci√≥n no ser√° en tiempo real como en Colab, pero puedes controlar la velocidad de reproducci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "xX3o9ecRfuPF"
   },
   "outputs": [],
   "source": [
    "def visualizar_video_notebook(video_path, rois_data, duracion_seg=None, inicio_seg=0):\n",
    "    \"\"\"\n",
    "    Visualiza el video en el notebook con detecciones\n",
    "\n",
    "    Args:\n",
    "        video_path: Ruta al video\n",
    "        rois_data: Datos de las ROIs\n",
    "        duracion_seg: Cu√°ntos segundos del video mostrar (None = hasta el final)\n",
    "        inicio_seg: Desde qu√© segundo empezar (0 = desde el inicio)\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"[ERROR] No se pudo abrir el video: {video_path}\")\n",
    "        return\n",
    "\n",
    "    # Informaci√≥n del video\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duracion_total = total_frames / fps if fps > 0 else 0\n",
    "\n",
    "    # Calcular frame inicial\n",
    "    frame_inicio = int(inicio_seg * fps)\n",
    "\n",
    "    # Posicionar el video en el frame inicial\n",
    "    if frame_inicio > 0:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_inicio)\n",
    "\n",
    "    # Calcular frames a procesar\n",
    "    if duracion_seg:\n",
    "        max_frames = frame_inicio + int(duracion_seg * fps)\n",
    "    else:\n",
    "        max_frames = total_frames\n",
    "\n",
    "    print(\"=\"*70)\n",
    "    print(\"VISUALIZADOR DE VIDEO\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Video: {video_path}\")\n",
    "    print(f\"FPS: {fps}\")\n",
    "    print(f\"Duraci√≥n total: {duracion_total:.1f} segundos\")\n",
    "    if inicio_seg > 0:\n",
    "        print(f\"Inicio: {inicio_seg:.1f}s\")\n",
    "    if duracion_seg:\n",
    "        print(f\"Mostrando: {duracion_seg:.1f} segundos\")\n",
    "    else:\n",
    "        print(f\"Mostrando: hasta el final ({duracion_total - inicio_seg:.1f}s)\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"Procesando video...\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # Widget para mostrar el video\n",
    "    image_widget = widgets.Image(format='jpeg', width=800)\n",
    "    display(image_widget)\n",
    "\n",
    "    frame_actual = frame_inicio\n",
    "    tiempo_inicio = time.time()\n",
    "\n",
    "    try:\n",
    "        while frame_actual < max_frames:\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                print(\"\\n[INFO] Fin del video alcanzado\")\n",
    "                break\n",
    "\n",
    "            # Procesar frame\n",
    "            frame_procesado = procesar_frame(frame, rois_data, frame_actual, fps, duracion_total)\n",
    "\n",
    "            # Convertir BGR a RGB para visualizaci√≥n\n",
    "            frame_rgb = cv2.cvtColor(frame_procesado, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Convertir a JPEG para mostrar en el widget\n",
    "            pil_img = Image.fromarray(frame_rgb)\n",
    "            buffer = BytesIO()\n",
    "            pil_img.save(buffer, format='JPEG', quality=85)\n",
    "            image_widget.value = buffer.getvalue()\n",
    "\n",
    "            frame_actual += 1\n",
    "\n",
    "            # Control de velocidad - actualizar cada N frames para que sea m√°s fluido\n",
    "            # En Jupyter local, mostrar cada 2 frames para mejor rendimiento\n",
    "            if frame_actual % 2 == 0:\n",
    "                time.sleep(1/fps)  # Pausar seg√∫n FPS para simular tiempo real\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n[INFO] Reproducci√≥n interrumpida\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[ERROR] Error durante la reproducci√≥n: {e}\")\n",
    "    finally:\n",
    "        cap.release()\n",
    "        tiempo_total = time.time() - tiempo_inicio\n",
    "        print(f\"\\n[OK] Reproducci√≥n finalizada\")\n",
    "        print(f\"Frames procesados: {frame_actual - frame_inicio}\")\n",
    "        print(f\"Tiempo total: {tiempo_total:.1f} segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5fZuHLffuPF"
   },
   "source": [
    "## 11. ‚ñ∂Ô∏è Ejecutar Visualizaci√≥n\n",
    "\n",
    "**Ejecuta esta celda para ver el video con las detecciones.**\n",
    "\n",
    "Puedes interrumpir la ejecuci√≥n en cualquier momento con el bot√≥n \"Stop\" de Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hzpOb1orfuPF",
    "outputId": "fbb5e49a-d7af-40dc-9e16-bfdd12917df6"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[INFO] Visualizacion deshabilitada (HABILITAR_VISUALIZACION = False)\n",
      "       Ejecuta la celda de exportacion para generar el video.\n"
     ]
    }
   ],
   "source": [
    "# Verificar si la visualizaci√≥n est√° habilitada\n",
    "if HABILITAR_VISUALIZACION:\n",
    "    visualizar_video_notebook(VIDEO_PATH, rois_data)\n",
    "else:\n",
    "    print(\"[INFO] Visualizacion deshabilitada (HABILITAR_VISUALIZACION = False)\")\n",
    "    print(\"       Ejecuta la celda de exportacion para generar el video.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "puQUxQS3fuPF"
   },
   "source": [
    "## 12. Exportar Video\n",
    "\n",
    "Esta seccion permite generar el video resultante con todas las detecciones.\n",
    "\n",
    "**IMPORTANTE:** Esta es la funcion principal del trabajo practico. Genera el video final para entregar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Xz89zXwvfuPF"
   },
   "outputs": [],
   "source": [
    "def exportar_video_procesado(video_path, rois_data, output_path=\"video_procesado.mp4\"):\n",
    "    \"\"\"Exporta el video procesado a un archivo\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"[ERROR] No se pudo abrir el video: {video_path}\")\n",
    "        return\n",
    "\n",
    "    # Obtener propiedades del video\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duracion = total_frames / fps if fps > 0 else 0\n",
    "\n",
    "    # Crear writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "    print(\"=\"*70)\n",
    "    print(\"EXPORTACION DE VIDEO\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Video de entrada: {video_path}\")\n",
    "    print(f\"Video de salida: {output_path}\")\n",
    "    print(f\"Resolucion: {width}x{height}\")\n",
    "    print(f\"FPS: {fps}\")\n",
    "    print(f\"Duracion: {duracion:.1f} segundos\")\n",
    "    print(f\"Total frames: {total_frames}\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"Procesando...\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    frame_actual = 0\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Procesar frame\n",
    "            frame_procesado = procesar_frame(frame, rois_data, frame_actual, fps, duracion)\n",
    "\n",
    "            # Escribir frame\n",
    "            out.write(frame_procesado)\n",
    "\n",
    "            frame_actual += 1\n",
    "\n",
    "            # Mostrar progreso cada 30 frames\n",
    "            if frame_actual % 30 == 0:\n",
    "                progreso = (frame_actual / total_frames) * 100\n",
    "                print(f\"Progreso: {progreso:.1f}% ({frame_actual}/{total_frames} frames)\", end=\"\\r\")\n",
    "\n",
    "    finally:\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        print(\"\\n\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"[OK] Video exportado exitosamente\")\n",
    "        print(f\"Archivo: {output_path}\")\n",
    "        print(f\"Frames procesados: {frame_actual}\")\n",
    "        print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kl3M5uxnfuPF",
    "outputId": "db407cea-38de-4120-d250-ba7bd9bcb97a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======================================================================\n",
      "EXPORTACION DE VIDEO\n",
      "======================================================================\n",
      "Video de entrada: video.mov\n",
      "Video de salida: video_procesado.mp4\n",
      "Resolucion: 1920x1080\n",
      "FPS: 29.987282746926663\n",
      "Duracion: 39.3 segundos\n",
      "Total frames: 1179\n",
      "======================================================================\n",
      "Procesando...\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "[OK] Video exportado exitosamente\n",
      "Archivo: video_procesado.mp4\n",
      "Frames procesados: 1179\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar exportacion del video completo\n",
    "exportar_video_procesado(VIDEO_PATH, rois_data, \"video_procesado.mp4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}